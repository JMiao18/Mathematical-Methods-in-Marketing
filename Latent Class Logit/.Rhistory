X2_predict_22 = as.matrix(X2_test)[,5:22] %*% ML_2$estimate[19:36]
X3_predict_23 = as.matrix(X3_test)[,5:22] %*% ML_2$estimate[19:36]
predict_21 = cbind(exp(X1_predict_11),exp(X2_predict_12),exp(X3_predict_13))
predict_22 = cbind(exp(X1_predict_21),exp(X2_predict_22),exp(X3_predict_23))
## predict_21 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 1
predict_21 = predict_21/rowSums(predict_21)
## predict_22 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_22 = predict_22/rowSums(predict_22)
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_2 = prob * predict_21 + (1 - prob) * predict_22
prediction_2 = max.col(predict_2)
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_2 = sum(prediction_2 == test_choice)/length(test_choice)
performance_2
Result_2
## The parameters for the first segment
par1 = rnorm(18)
## The parameters for the second segment
par2 = rnorm(18)
## The parameters for the third segment
par3 = rnorm(18)
## The parameter for the likelihood that a randomly chosen individual belongs to segment 1
p3 = exp(rnorm(3))
p3 = p3/sum(p3)
## The combined parameters are
par_3 = t(cbind(t(par1),t(par2),t(par3),t(p3[1:2])))
N = 1918
ll_3 <- function(beta)
{
res = 0
## To calculate the likelohood for the first segment
M11 = as.matrix(train_set)[,1:18] %*% beta[1:18]
M12 = as.matrix(train_set)[,19:36] %*% beta[1:18]
M13 = as.matrix(train_set)[,37:54] %*% beta[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
## The likelihood for each of the three alternatives in the first segment
M1 = M1 / rowSums(M1)
M21 = as.matrix(train_set)[,1:18] %*% beta[19:36]
M22 = as.matrix(train_set)[,19:36] %*% beta[19:36]
M23 = as.matrix(train_set)[,37:54] %*% beta[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
## The likelihood for each of the three alternatives in the first segment
M2 = M2 / rowSums(M2)
M31 = as.matrix(train_set)[,1:18] %*% beta[37:54]
M32 = as.matrix(train_set)[,19:36] %*% beta[37:54]
M33 = as.matrix(train_set)[,37:54] %*% beta[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
## The likelihood for each of the three alternatives in the first segment
M3 = M3 / rowSums(M3)
## Given that the consumer belongs to Segment 1, what is the probability for him to choose Alternative i?
prob_1 = M1[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 2, what is the probability for him to choose Alternative i?
prob_2 = M2[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 2, what is the probability for him to choose Alternative i?
prob_3 = M3[cbind(seq(1,length(train_choice)),train_choice)]
## This transformation guarantees that the likelihood for each segment is within the range of (0,1)
probability_1 = beta[55]
probability_2 = beta[56]
for (i in 1:137)
{
MP = c()
MP[i] =  probability_1 * cumprod(prob_1[(14*(i-1)+1):(14*i)])[14] + probability_2 * cumprod(prob_2[(14*(i-1)+1):(14*i)])[14] + (1 - probability_2 - probability_1) * cumprod(prob_3[(14*(i-1)+1):(14*i)])[14]
res = res -log(MP[i])
}
return (res)
}
ML_3 = nlm(ll_3,par_3,hessian = TRUE)
mode = ML_3$estimate
SE = sqrt(diag(solve(ML_3$hessian)))
Tvalue = mode/SE
ll = 2*ML_3$minimum
Result_3 = cbind(Estimate = mode, SE= SE, Tvalue = Tvalue, minusll = ll)
round(Result_3,2)
##  This is the estimates for pi_i(the market share of the first segment)
pi_1 = ML_3$estimate[55]
pi_2 = ML_3$estimate[56]
# ## NExt, I am going to obtain the individual-level estimate of segment membership using Bayes rule.
## The likelihood for each of the three alternatives in the first segment
M11 = as.matrix(train_set)[,1:18] %*% ML_3$estimate[1:18]
M12 = as.matrix(train_set)[,19:36] %*% ML_3$estimate[1:18]
M13 = as.matrix(train_set)[,37:54] %*% ML_3$estimate[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
M1 = M1 / rowSums(M1)
## M11 is the probability for individual i's actual choice in Segment 1
M11 = M1[cbind(1:(137*14),train_choice[1:(137*14)])]
## The likelihood for each of the three alternatives in the second segment
M21 = as.matrix(train_set)[,1:18] %*% ML_3$estimate[19:36]
M22 = as.matrix(train_set)[,19:36] %*% ML_3$estimate[19:36]
M23 = as.matrix(train_set)[,37:54] %*% ML_3$estimate[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
M2 = M2 / rowSums(M2)
## M11 is the probability for individual i's actual choice in Segment 2
M12 = M2[cbind(1:(14*137),train_choice[1:(14*137)])]
## The likelihood for each of the three alternatives in the third segment
M31 = as.matrix(train_set)[,1:18] %*% ML_3$estimate[37:54]
M32 = as.matrix(train_set)[,19:36] %*% ML_3$estimate[37:54]
M33 = as.matrix(train_set)[,37:54] %*% ML_3$estimate[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
M3 = M3 / rowSums(M3)
## M11 is the probability for individual i's actual choice in Segment 2
M13 = M3[cbind(1:(14*137),train_choice[1:(14*137)])]
## The individual-level estimates of segment membership using Bayes Rule
## What is the orobability for each individual to belong to Segment 1?
prob <- rep(0,137*2)
prob = matrix(prob, 137,2)
for (i in 1:137)
{
prob[i,1] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14+(i-1)*14)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14+(i-1)*14)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14+(i-1)*14)])[14]) + ((1 - pi_2 - pi_1) * cumprod(M13[(1+(i-1)*14):(14+(i-1)*14)])[14]))
prob[i,2] = (pi_2 * (cumprod(M12[(1+(i-1)*14):(14+(i-1)*14)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14+(i-1)*14)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14+(i-1)*14)])[14]) + ((1 - pi_2 - pi_1) * cumprod(M13[(1+(i-1)*14):(14+(i-1)*14)])[14]))
}
## The vector prob is the probability for each individual to choose Segment 1
##########################################
# ## Another Method which is theoretical correct but practically infeasible
# cumprod(M11[(1+(2-1)*14):(14+(2-1)*14)])[14]
# cum_M11 = cumprod(M11)
# cum_M12 = cumprod(M12)
# cumprod(M11)[14]/(cumprod(M11)[14]+cumprod(M12)[14])
#
# a <- 1:(137*14)
# b_11 <- cum_M11[seq(14, 137*14, 14)]
# b_11_tmp <- t(cbind(1,t(b_11)))
# b_11_tem = b_11_tmp[1:137]
# b_11/b_11_tem
##########################################
## Then I am going to do the Cross-Validation
##  The expected probability for each alternative in Segment 1
X1_predict_11 = as.matrix(X1_test)[,5:22] %*% ML_3$estimate[1:18]
X2_predict_12 = as.matrix(X2_test)[,5:22] %*% ML_3$estimate[1:18]
X3_predict_13 = as.matrix(X3_test)[,5:22] %*% ML_3$estimate[1:18]
##  The expected probability for each alternative in Segment 2
X1_predict_21 = as.matrix(X1_test)[,5:22] %*% ML_3$estimate[19:36]
X2_predict_22 = as.matrix(X2_test)[,5:22] %*% ML_3$estimate[19:36]
X3_predict_23 = as.matrix(X3_test)[,5:22] %*% ML_3$estimate[19:36]
##  The expected probability for each alternative in Segment 3
X1_predict_31 = as.matrix(X1_test)[,5:22] %*% ML_3$estimate[37:54]
X2_predict_32 = as.matrix(X2_test)[,5:22] %*% ML_3$estimate[37:54]
X3_predict_33 = as.matrix(X3_test)[,5:22] %*% ML_3$estimate[37:54]
predict_31 = cbind(exp(X1_predict_11),exp(X2_predict_12),exp(X3_predict_13))
predict_32 = cbind(exp(X1_predict_21),exp(X2_predict_22),exp(X3_predict_23))
predict_33 = cbind(exp(X1_predict_31),exp(X2_predict_32),exp(X3_predict_33))
## predict_31 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 1
predict_31 = predict_31/rowSums(predict_31)
## predict_32 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_32 = predict_32/rowSums(predict_32)
## predict_33 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_33 = predict_33/rowSums(predict_33)
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_3 = prob[,1] * predict_31 + prob[,2] * predict_32 + (1 - prob[,1] - prob[,2]) *  predict_33
prediction_3 = max.col(predict_3)
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_3 = sum(prediction_3 == test_choice)/length(test_choice)
performance_3
Result_3
View(Result_2)
performance_2
Result_2
par1 = rnorm(18)
## The parameters for the second segment
par2 = rnorm(18)
## The parameters for the third segment
par3 = rnorm(18)
## The parameters for the fourth segment
par4 = rnorm(18)
## The parameter for the likelihood that a randomly chosen individual belongs to segment 1
p4 = exp(rnorm(4))
p4 = p4/sum(p4)
## The combined parameters are
par_4 = t(cbind(t(par1),t(par2),t(par3),t(par4),t(p4[1:3])))
N = 1918
ll_4 <- function(beta)
{
res = 0
## To calculate the likelohood for the first segment
M11 = as.matrix(train_set)[,1:18] %*% beta[1:18]
M12 = as.matrix(train_set)[,19:36] %*% beta[1:18]
M13 = as.matrix(train_set)[,37:54] %*% beta[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
## The likelihood for each of the three alternatives in the first segment
M1 = M1 / rowSums(M1)
M21 = as.matrix(train_set)[,1:18] %*% beta[19:36]
M22 = as.matrix(train_set)[,19:36] %*% beta[19:36]
M23 = as.matrix(train_set)[,37:54] %*% beta[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
## The likelihood for each of the three alternatives in the second segment
M2 = M2 / rowSums(M2)
M31 = as.matrix(train_set)[,1:18] %*% beta[37:54]
M32 = as.matrix(train_set)[,19:36] %*% beta[37:54]
M33 = as.matrix(train_set)[,37:54] %*% beta[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
## The likelihood for each of the three alternatives in the third segment
M3 = M3 / rowSums(M3)
M41 = as.matrix(train_set)[,1:18] %*% beta[55:72]
M42 = as.matrix(train_set)[,19:36] %*% beta[55:72]
M43 = as.matrix(train_set)[,37:54] %*% beta[55:72]
M4 = cbind(exp(M41),exp(M42),exp(M43))
## The likelihood for each of the three alternatives in the fourth segment
M4 = M4 / rowSums(M4)
## Given that the consumer belongs to Segment 1, what is the probability for him to choose Alternative i?
prob_1 = M1[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 2, what is the probability for him to choose Alternative i?
prob_2 = M2[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 3, what is the probability for him to choose Alternative i?
prob_3 = M3[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 3, what is the probability for him to choose Alternative i?
prob_4 = M4[cbind(seq(1,length(train_choice)),train_choice)]
## This transformation guarantees that the likelihood for each segment is within the range of (0,1)
probability_1 = beta[73]
probability_2 = beta[74]
probability_3 = beta[75]
for (i in 1:137)
{
MP = c()
MP[i] =  probability_1 * cumprod(prob_1[(14*(i-1)+1):(14*i)])[14] + probability_2 * cumprod(prob_2[(14*(i-1)+1):(14*i)])[14] + probability_3 * cumprod(prob_3[(14*(i-1)+1):(14*i)])[14] + (1 - probability_1 - probability_2 - probability_3) * cumprod(prob_4[(14*(i-1)+1):(14*i)])[14]
res = res -log(MP[i])
}
return (res)
}
ML_4 = nlm(ll_4,par_4,hessian = TRUE)
mode = ML_4$estimate
SE = sqrt(diag(solve(ML_4$hessian)))
Tvalue = mode/SE
ll = 2*ML_4$minimum
Result_4 = cbind(Estimate = mode, SE= SE, Tvalue = Tvalue, minusll = ll)
round(Result_4,2)
##  This is the estimates for pi_i(the market share of the first segment)
pi_1 = ML_4$estimate[73]
pi_2 = ML_4$estimate[74]
pi_3 = ML_4$estimate[75]
## Concise Expression
## The likelihood for each of the three alternatives in the first segment
M11 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[1:18]
M12 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[1:18]
M13 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
M1 = M1 / rowSums(M1)
## M11 is the probability for individual i's actual choice in Segment 1
M11 = M1[cbind(1:(137*14),train_choice[1:(137*14)])]
## The likelihood for each of the three alternatives in the second segment
M21 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[19:36]
M22 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[19:36]
M23 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
M2 = M2 / rowSums(M2)
## M11 is the probability for individual i's actual choice in Segment 2
M12 = M2[cbind(1:(14*137),train_choice[1:(14*137)])]
## The likelihood for each of the three alternatives in the third segment
M31 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[37:54]
M32 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[37:54]
M33 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
M3 = M3 / rowSums(M3)
## M11 is the probability for individual i's actual choice in Segment 2
M13 = M3[cbind(1:(14*137),train_choice[1:(14*137)])]
## The likelihood for each of the three alternatives in the fourth segment
M41 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[55:72]
M42 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[55:72]
M43 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[55:72]
M4 = cbind(exp(M41),exp(M42),exp(M43))
M4 = M4 / rowSums(M4)
## M11 is the probability for individual i's actual choice in Segment 2
M14 = M4[cbind(1:(14*137),train_choice[1:(14*137)])]
## The individual-level estimates of segment membership using Bayes Rule
## What is the orobability for each individual to belong to Segment 1?
prob <- rep(0,137*3)
prob = matrix(prob, 137,3)
for (i in 1:137)
{
prob[i,1] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
prob[i,2] = (pi_2 * (cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
prob[i,3] = (pi_3 * (cumprod(M13[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
}
## The vector prob is the probability for each individual to choose Segment 1
##########################################
# ## Another Method which is theoretical correct but practically infeasible
# cumprod(M11[(1+(2-1)*14):(14+(2-1)*14)])[14]
# cum_M11 = cumprod(M11)
# cum_M12 = cumprod(M12)
# cumprod(M11)[14]/(cumprod(M11)[14]+cumprod(M12)[14])
#
# a <- 1:(137*14)
# b_11 <- cum_M11[seq(14, 137*14, 14)]
# b_11_tmp <- t(cbind(1,t(b_11)))
# b_11_tem = b_11_tmp[1:137]
# b_11/b_11_tem
##########################################
## ***********************************************
## Then I am going to do the Cross-Validation
##  The expected probability for each alternative in Segment 1
## Segment 1 -- Choice 1
X1_predict_11 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[1:18]
## Segment 1 -- Choice 2
X2_predict_12 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[1:18]
## Segment 1 -- Choice 3
X3_predict_13 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[1:18]
##  The expected probability for each alternative in Segment 2
## Segment 2 -- Choice 1
X1_predict_21 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[19:36]
## Segment 2 -- Choice 2
X2_predict_22 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[19:36]
## Segment 2 -- Choice 3
X3_predict_23 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[19:36]
##  The expected probability for each alternative in Segment 3
## Segment 3 -- Choice 1
X1_predict_31 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[37:54]
## Segment 3 -- Choice 2
X2_predict_32 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[37:54]
## Segment 3 -- Choice 3
X3_predict_33 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[37:54]
##  The expected probability for each alternative in Segment 4
## Segment 4 -- Choice 1
X1_predict_41 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[55:72]
## Segment 4 -- Choice 2
X2_predict_42 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[55:72]
## Segment 4 -- Choice 3
X3_predict_43 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[55:72]
predict_41 = cbind(exp(X1_predict_11),exp(X2_predict_12),exp(X3_predict_13))
predict_42 = cbind(exp(X1_predict_21),exp(X2_predict_22),exp(X3_predict_23))
predict_43 = cbind(exp(X1_predict_31),exp(X2_predict_32),exp(X3_predict_33))
predict_44 = cbind(exp(X1_predict_41),exp(X2_predict_42),exp(X3_predict_43))
## predict_41 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 1
predict_41 = predict_41/rowSums(predict_41)
## predict_42 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_42 = predict_42/rowSums(predict_42)
predict_43 = predict_43/rowSums(predict_43)
predict_44 = predict_44/rowSums(predict_44)
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_4 = prob[,1] * predict_41 + prob[,2] * predict_42 + prob[,3] * predict_43 + (1 - prob[,1] - prob[,2] - prob[,3]) * predict_44
prediction_4 = max.col(predict_4)
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_4 = sum(prediction_4 == test_choice)/length(test_choice)
performance_4
Result_4
View(Result_2)
result = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent/newresults.csv",header = TRUE)
attach(result)
summary(result)
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
result = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent/newresults.csv",header = TRUE)
attach(result)
summary(result)
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
result = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent/results.csv",header = TRUE)
attach(result)
summary(result)
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
result = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/Latent Class Logit/Mathematical Models in Marketing (Kohli)/latent/results.csv",header = TRUE)
attach(result)
summary(result)
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
predict_21
predict_2
cbind(predict_21,predict_22
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_2 = prob * predict_21 + (1 - prob) * predict_22
prediction_2 = max.col(predict_2)
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_2 = sum(prediction_2 == test_choice)/length(test_choice)
performance_2
Result_2
cbind(predict_21,predict_22)
ML_2
Result_2
performance_2 = sum(prediction_2 == test_choice)/length(test_choice)
performance_2
Result_2
pi_1 = ML_2$estimate[37]
## Concise Expression
## The likelihood for each of the three alternatives in the first segment
M11 = as.matrix(train_set)[,1:18] %*% ML_2$estimate[1:18]
M12 = as.matrix(train_set)[,19:36] %*% ML_2$estimate[1:18]
M13 = as.matrix(train_set)[,37:54] %*% ML_2$estimate[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
M1 = M1 / rowSums(M1)
## M11 is the probability for individual i's actual choice in Segment 1
M11 = M1[cbind(1:(137*14),train_choice[1:(137*14)])]
## The likelihood for each of the three alternatives in the second segment
M21 = as.matrix(train_set)[,1:18] %*% ML_2$estimate[19:36]
M22 = as.matrix(train_set)[,19:36] %*% ML_2$estimate[19:36]
M23 = as.matrix(train_set)[,37:54] %*% ML_2$estimate[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
M2 = M2 / rowSums(M2)
## M11 is the probability for individual i's actual choice in Segment 2
M12 = M2[cbind(1:(14*137),train_choice[1:(14*137)])]
## The individual-level estimates of segment membership using Bayes Rule
## What is the orobability for each individual to belong to Segment 1?
prob <- rep(0,137*3)
prob = matrix(prob, 137,3)
for (i in 1:137)
{
prob[i,1] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
prob[i,2] = (pi_2 * (cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
}
## The vector prob is the probability for each individual to choose Segment 1
##########################################
# ## Another Method which is theoretical correct but practically infeasible
# cumprod(M11[(1+(2-1)*14):(14+(2-1)*14)])[14]
# cum_M11 = cumprod(M11)
# cum_M12 = cumprod(M12)
# cumprod(M11)[14]/(cumprod(M11)[14]+cumprod(M12)[14])
#
# a <- 1:(137*14)
# b_11 <- cum_M11[seq(14, 137*14, 14)]
# b_11_tmp <- t(cbind(1,t(b_11)))
# b_11_tem = b_11_tmp[1:137]
# b_11/b_11_tem
##########################################
## ***********************************************
## Then I am going to do the Cross-Validation
##  The expected probability for each alternative in Segment 1
## Segment 1 -- Choice 1
X1_predict_11 = as.matrix(X1_test)[,5:22] %*% ML_2$estimate[1:18]
## Segment 1 -- Choice 2
X2_predict_12 = as.matrix(X2_test)[,5:22] %*% ML_2$estimate[1:18]
## Segment 1 -- Choice 3
X3_predict_13 = as.matrix(X3_test)[,5:22] %*% ML_2$estimate[1:18]
##  The expected probability for each alternative in Segment 2
## Segment 2 -- Choice 1
X1_predict_21 = as.matrix(X1_test)[,5:22] %*% ML_2$estimate[19:36]
## Segment 2 -- Choice 2
X2_predict_22 = as.matrix(X2_test)[,5:22] %*% ML_2$estimate[19:36]
## Segment 2 -- Choice 3
X3_predict_23 = as.matrix(X3_test)[,5:22] %*% ML_2$estimate[19:36]
##  The expected probability for each alternative in Segment 3
predict_21 = cbind(exp(X1_predict_11),exp(X2_predict_12),exp(X3_predict_13))
predict_22 = cbind(exp(X1_predict_21),exp(X2_predict_22),exp(X3_predict_23))
## predict_41 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 1
predict_21 = predict_21/rowSums(predict_21)
## predict_42 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_22 = predict_22/rowSums(predict_22)
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_2 = prob[,1] * predict_21 + (1 - prob[,1]) * predict_22
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_2 = sum(prediction_2 == test_choice)/length(test_choice)
performance_2
Result_2
predict_2
predict_21
cbind(predict_21,predict_22)
prob
pi_1 = ML_2$estimate[37]
## Concise Expression
## The likelihood for each of the three alternatives in the first segment
M11 = as.matrix(train_set)[,1:18] %*% ML_2$estimate[1:18]
M12 = as.matrix(train_set)[,19:36] %*% ML_2$estimate[1:18]
M13 = as.matrix(train_set)[,37:54] %*% ML_2$estimate[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
M1 = M1 / rowSums(M1)
## M11 is the probability for individual i's actual choice in Segment 1
M11 = M1[cbind(1:(137*14),train_choice[1:(137*14)])]
## The likelihood for each of the three alternatives in the second segment
M21 = as.matrix(train_set)[,1:18] %*% ML_2$estimate[19:36]
M22 = as.matrix(train_set)[,19:36] %*% ML_2$estimate[19:36]
M23 = as.matrix(train_set)[,37:54] %*% ML_2$estimate[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
M2 = M2 / rowSums(M2)
## M11 is the probability for individual i's actual choice in Segment 2
M12 = M2[cbind(1:(14*137),train_choice[1:(14*137)])]
## The individual-level estimates of segment membership using Bayes Rule
## What is the orobability for each individual to belong to Segment 1?
prob <- rep(0,137)
for (i in 1:137)
{
prob[i] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))
}
prob
cbind(prob,1-prob)
round(cbind(prob,1-prob),2)
pi_1
prob[i] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + ((1-pi_1) * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))
prob <- rep(0,137)
for (i in 1:137)
{
prob[i] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + ((1-pi_1) * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))
}
round(cbind(prob,1-prob),2)
write.csv(round(cbind(prob,1-prob),2),file="M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/Latent Class Logit/Mathematical Models in Marketing (Kohli)/latent/newseg.csv")
Result_2
