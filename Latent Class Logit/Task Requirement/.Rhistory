result = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent/newresults.csv",header = TRUE)
attach(result)
summary(result)
plot(number.of.classe[1:5],AIC[1:5],type = "b")
plot(number.of.classe[1:5],BIC[1:5],type="b")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6))
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2000,4000))
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000))
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "BVIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BVIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between NUmber of Classes and AIC")
plot(number.of.classe[1:5],AIC[1:5],type = "b",xlim = c(0,6),ylim=c(2500,4000)
,xlab = "Number of Classes", ylab = "AIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and AIC")
plot(number.of.classe[1:5],BIC[1:5],type="b",xlim = c(0,6),ylim=c(1500,4000)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0,1)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8)
,xlab = "Number of Classes", ylab = "BIC", main = "The relationship between Number of Classes and BIC")
plot(number.of.classe[1:5],rate.of.correct.predictions[1:5],type = "b",xlim = c(0,6),ylim=c(0.4,0.8) ,xlab = "Number of Classes", ylab = "Proportion of Correct Predictions", main = "The relationship between Number of Classes and Predictability")
data = read.csv(file = "M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent/data_ipad.csv",head = TRUE)
attach(data)
summary(data)
## Modelling Step 1: Set up Training Set and Dev Set
random_factor = sample(1:15,137,replace = TRUE)
determinant_factor = (1:137)*15 - 15
## The index for Dev Set is the summation of Random and Deterministic.
index = random_factor + determinant_factor
dev = data[which(choice_set_id  %in%  index) ,]
train = data[which(!(choice_set_id  %in%  index)) ,]
## Model 1: Fit an aggregate model without any segment
## In the training set,
X1_train = subset(train, alternative_id_in_set == 1)
X2_train = subset(train, alternative_id_in_set == 2)
X3_train = subset(train, alternative_id_in_set == 3)
## In the test set,``
X1_test = subset(dev, alternative_id_in_set == 1)
X2_test = subset(dev, alternative_id_in_set == 2)
X3_test = subset(dev, alternative_id_in_set == 3)
## The dependent variable
train_choice = X1_train$choice
test_choice = X1_test$choice
train_set = cbind(X1_train[,5:22],X2_train[,5:22],X3_train[,5:22])
test_set = cbind(X1_test[,5:22],X2_test[,5:22],X3_test[,5:22])
## The parameters for the first segment
par1 = rnorm(18)
## The parameters for the second segment
par2 = rnorm(18)
## The parameters for the third segment
par3 = rnorm(18)
## The parameters for the fourth segment
par4 = rnorm(18)
## The parameter for the likelihood that a randomly chosen individual belongs to segment 1
p4 = exp(rnorm(4))
p4 = p4/sum(p4)
## The combined parameters are
par_4 = t(cbind(t(par1),t(par2),t(par3),t(par4),t(p4[1:3])))
N = 1918
ll_4 <- function(beta)
{
res = 0
## To calculate the likelohood for the first segment
M11 = as.matrix(train_set)[,1:18] %*% beta[1:18]
M12 = as.matrix(train_set)[,19:36] %*% beta[1:18]
M13 = as.matrix(train_set)[,37:54] %*% beta[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
## The likelihood for each of the three alternatives in the first segment
M1 = M1 / rowSums(M1)
M21 = as.matrix(train_set)[,1:18] %*% beta[19:36]
M22 = as.matrix(train_set)[,19:36] %*% beta[19:36]
M23 = as.matrix(train_set)[,37:54] %*% beta[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
## The likelihood for each of the three alternatives in the second segment
M2 = M2 / rowSums(M2)
M31 = as.matrix(train_set)[,1:18] %*% beta[37:54]
M32 = as.matrix(train_set)[,19:36] %*% beta[37:54]
M33 = as.matrix(train_set)[,37:54] %*% beta[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
## The likelihood for each of the three alternatives in the third segment
M3 = M3 / rowSums(M3)
M41 = as.matrix(train_set)[,1:18] %*% beta[55:72]
M42 = as.matrix(train_set)[,19:36] %*% beta[55:72]
M43 = as.matrix(train_set)[,37:54] %*% beta[55:72]
M4 = cbind(exp(M41),exp(M42),exp(M43))
## The likelihood for each of the three alternatives in the fourth segment
M4 = M4 / rowSums(M4)
## Given that the consumer belongs to Segment 1, what is the probability for him to choose Alternative i?
prob_1 = M1[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 2, what is the probability for him to choose Alternative i?
prob_2 = M2[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 3, what is the probability for him to choose Alternative i?
prob_3 = M3[cbind(seq(1,length(train_choice)),train_choice)]
## Given that the consumer belongs to Segment 3, what is the probability for him to choose Alternative i?
prob_4 = M4[cbind(seq(1,length(train_choice)),train_choice)]
## This transformation guarantees that the likelihood for each segment is within the range of (0,1)
probability_1 = beta[73]
probability_2 = beta[74]
probability_3 = beta[75]
for (i in 1:137)
{
MP = c()
MP[i] =  probability_1 * cumprod(prob_1[(14*(i-1)+1):(14*i)])[14] + probability_2 * cumprod(prob_2[(14*(i-1)+1):(14*i)])[14] + probability_3 * cumprod(prob_3[(14*(i-1)+1):(14*i)])[14] + (1 - probability_1 - probability_2 - probability_3) * cumprod(prob_4[(14*(i-1)+1):(14*i)])[14]
res = res -log(MP[i])
}
return (res)
}
ML_4 = nlm(ll_4,par_4,hessian = TRUE)
mode = ML_4$estimate
SE = sqrt(diag(solve(ML_4$hessian)))
Tvalue = mode/SE
ll = 2*ML_4$minimum
Result_4 = cbind(Estimate = mode, SE= SE, Tvalue = Tvalue, minusll = ll)
round(Result_4,2)
##  This is the estimates for pi_i(the market share of the first segment)
pi_1 = ML_4$estimate[73]
pi_2 = ML_4$estimate[74]
pi_3 = ML_4$estimate[75]
## Concise Expression
## The likelihood for each of the three alternatives in the first segment
M11 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[1:18]
M12 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[1:18]
M13 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[1:18]
M1 = cbind(exp(M11),exp(M12),exp(M13))
M1 = M1 / rowSums(M1)
## M11 is the probability for individual i's actual choice in Segment 1
M11 = M1[cbind(1:(137*14),train_choice[1:(137*14)])]
## The likelihood for each of the three alternatives in the second segment
M21 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[19:36]
M22 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[19:36]
M23 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[19:36]
M2 = cbind(exp(M21),exp(M22),exp(M23))
M2 = M2 / rowSums(M2)
## M11 is the probability for individual i's actual choice in Segment 2
M12 = M2[cbind(1:(14*137),train_choice[1:(14*137)])]
## The likelihood for each of the three alternatives in the third segment
M31 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[37:54]
M32 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[37:54]
M33 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[37:54]
M3 = cbind(exp(M31),exp(M32),exp(M33))
M3 = M3 / rowSums(M3)
## M11 is the probability for individual i's actual choice in Segment 2
M13 = M3[cbind(1:(14*137),train_choice[1:(14*137)])]
## The likelihood for each of the three alternatives in the fourth segment
M41 = as.matrix(train_set)[,1:18] %*% ML_4$estimate[55:72]
M42 = as.matrix(train_set)[,19:36] %*% ML_4$estimate[55:72]
M43 = as.matrix(train_set)[,37:54] %*% ML_4$estimate[55:72]
M4 = cbind(exp(M41),exp(M42),exp(M43))
M4 = M4 / rowSums(M4)
## M11 is the probability for individual i's actual choice in Segment 2
M14 = M4[cbind(1:(14*137),train_choice[1:(14*137)])]
## The individual-level estimates of segment membership using Bayes Rule
## What is the orobability for each individual to belong to Segment 1?
prob <- rep(0,137*3)
prob = matrix(prob, 137,3)
for (i in 1:137)
{
prob[i,1] = (pi_1 * (cumprod(M11[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
prob[i,2] = (pi_2 * (cumprod(M12[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
prob[i,3] = (pi_3 * (cumprod(M13[(1+(i-1)*14):(14 * i)])[14]))/((pi_1 * cumprod(M11[(1+(i-1)*14):(14 * i)])[14]) + (pi_2 * cumprod(M12[(1+(i-1)*14):(14 * i)])[14]) + (pi_3 * cumprod(M13[(1+(i-1)*14):(14 * i)])[14]) + ((1 - pi_2 - pi_1 - pi_3) * cumprod(M14[(1+(i-1)*14):(14 * i)])[14]))
}
## The vector prob is the probability for each individual to choose Segment 1
##########################################
# ## Another Method which is theoretical correct but practically infeasible
# cumprod(M11[(1+(2-1)*14):(14+(2-1)*14)])[14]
# cum_M11 = cumprod(M11)
# cum_M12 = cumprod(M12)
# cumprod(M11)[14]/(cumprod(M11)[14]+cumprod(M12)[14])
#
# a <- 1:(137*14)
# b_11 <- cum_M11[seq(14, 137*14, 14)]
# b_11_tmp <- t(cbind(1,t(b_11)))
# b_11_tem = b_11_tmp[1:137]
# b_11/b_11_tem
##########################################
## ***********************************************
## Then I am going to do the Cross-Validation
##  The expected probability for each alternative in Segment 1
## Segment 1 -- Choice 1
X1_predict_11 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[1:18]
## Segment 1 -- Choice 2
X2_predict_12 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[1:18]
## Segment 1 -- Choice 3
X3_predict_13 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[1:18]
##  The expected probability for each alternative in Segment 2
## Segment 2 -- Choice 1
X1_predict_21 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[19:36]
## Segment 2 -- Choice 2
X2_predict_22 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[19:36]
## Segment 2 -- Choice 3
X3_predict_23 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[19:36]
##  The expected probability for each alternative in Segment 3
## Segment 3 -- Choice 1
X1_predict_31 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[37:54]
## Segment 3 -- Choice 2
X2_predict_32 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[37:54]
## Segment 3 -- Choice 3
X3_predict_33 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[37:54]
##  The expected probability for each alternative in Segment 4
## Segment 4 -- Choice 1
X1_predict_41 = as.matrix(X1_test)[,5:22] %*% ML_4$estimate[55:72]
## Segment 4 -- Choice 2
X2_predict_42 = as.matrix(X2_test)[,5:22] %*% ML_4$estimate[55:72]
## Segment 4 -- Choice 3
X3_predict_43 = as.matrix(X3_test)[,5:22] %*% ML_4$estimate[55:72]
predict_41 = cbind(exp(X1_predict_11),exp(X2_predict_12),exp(X3_predict_13))
predict_42 = cbind(exp(X1_predict_21),exp(X2_predict_22),exp(X3_predict_23))
predict_43 = cbind(exp(X1_predict_31),exp(X2_predict_32),exp(X3_predict_33))
predict_44 = cbind(exp(X1_predict_41),exp(X2_predict_42),exp(X3_predict_43))
## predict_41 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 1
predict_41 = predict_41/rowSums(predict_41)
## predict_42 is the predicted probability for each individual to choose each alternative given that he belongs to Segment 2
predict_42 = predict_42/rowSums(predict_42)
predict_43 = predict_43/rowSums(predict_43)
predict_44 = predict_44/rowSums(predict_44)
## The vector prob is the probability for each individual to choose Segment 1
## We can use the posterior segment membership probability to estimate the probability that individual i chooses alternative j
predict_4 = prob[,1] * predict_41 + prob[,2] * predict_42 + prob[,3] * predict_43 + (1 - prob[,1] - prob[,2] - prob[,3]) * predict_44
prediction_4 = max.col(predict_4)
## The performance of the model without segments is evaluated by the proportion of correct predictions.
performance_4 = sum(prediction_4 == test_choice)/length(test_choice)
performance_4
Result_4
prob
1-rowSUm(prob)
1-rowSum(prob)
?rowsum
rowsum(prob)
prob
rowSums(prob)
1-rowSums(prob)
se4 = 1-rowSums(prob)
cbind(prob,se4)
rowSums(_)
full = cbind(prob,se4)
rowSums(full)
round(full,2)
pwd
setwd(M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent)
setwd("M:/A Master of Science in Marketing Sciences/Mathematical Models in Marketing (Kohli)/latent")
write.csv(full,"seg.csv")
rm(list = ls())
