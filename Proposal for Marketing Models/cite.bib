@article{Narasimhan2015,
abstract = {In this editorial accompanying the Special Section on Marketing Science in Emerging Markets (MSEM), we describe how research on emerging markets can contribute to richer theoretical and substantive understanding of markets and marketing. Such research can also aid in providing managerial guidance on how to operate in emerging markets. We conclude with a description of the selection and review process for the special section and an overview of the four papers being published.},
author = {Narasimhan, Laxman and Srinivasan, Kannan and Sudhir, K.},
doi = {10.1287/mksc.2015.0934},
file = {:C$\backslash$:/Users/Jin Miao/Desktop/PhD Application/Editorial Marketing Science in Emerging Markets.pdf:pdf},
issn = {0732-2399},
journal = {Marketing Science},
mendeley-groups = {Online Review/Paper},
number = {4},
pages = {473--479},
title = {{Editorial —Marketing Science in Emerging Markets}},
url = {http://pubsonline.informs.org/doi/10.1287/mksc.2015.0934},
volume = {34},
year = {2015}
}


@online{amazon,
    author    = "Amazon",
    title     = "About Customer Reviews",
    url       = "https://www.amazon.com/gp/help/customer/display.html?nodeId=201145120",
    keywords  = "review"
}

@online{taobao,
    author    = "Taobao",
    title     = "Fake Transactions",
    url       = "https://daxue.taobao.com/markets/daxue/jy_tdtw",
    keywords  = "review"
}

@online{maijia,
    author    = "maijia.com",
    title     = "Punishment for Fake Transactions",
    url       = "http://www.maijia.com/software/tutorial/1014737",
    keywords  = "review"
}

@online{sina,
    author    = "sina.com",
    title     = "Malign Reviews from Competitors",
    url       = "http://tech.sina.com.cn/i/2013-07-29/09098584137.shtml",
    keywords  = "review"
}

@article{Wu2015,
abstract = {This paper investigates the economic value of online reviews for consumers and restaurants. We use a data set from Dianping.com, a leading Chinese website providing user-generated reviews, to study how consumers learn, from reading online reviews, the quality and cost of restaurant dining. We propose a learning model with three novel features: (1) different reviews offer different informational value to different types of consumers; (2) consumers learn their own preferences, and not the distribution of preferences among the entire population, for multiple product attributes; and (3) consumers update not only the expectation but also the variance of their preferences. Based on estimation results, we conduct a series of counterfactual experiments and find that the value from Dianping is about 7 CNY for each user, and about 8.6 CNY from each user for the reviewed restaurants in this study. The majority of the value comes from reviews on restaurant quality, and contextual comments are mor)},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1287/mksc.2015.0926},
author = {Wu, Chunhua and Che, Hai and Chan, Tat Y and Lu, Xianghua},
doi = {10.1287/mksc.2015.0926},
eprint = {/dx.doi.org/10.1287/mksc.2015.0926},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Applied Multivariate Statistics/Project/The Economic Value of Online Reviews.pdf:pdf},
isbn = {0732-2399$\backslash$r1526-548X},
issn = {07322399},
journal = {Marketing Science},
keywords = {CONSUMERS -- Psychology,DINNERS {\&} dining,EVALUATION,QUALITY of service,RESTAURANTS,WEBSITES,consumer choice under uncertainty,economic value to consumer and firm,learning,online reviews,user-generated content},
mendeley-groups = {Online Review},
number = {5},
pages = {739--754},
primaryClass = {http:},
title = {{The Economic Value of Online Reviews.}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=109946278{\&}site=ehost-live},
volume = {34},
year = {2015}
}

@article{Proserpio2017,
abstract = {Failure to meet a consumer's expectations can result in a negative review, which can have a lasting, damaging impact on a firm's reputation, and its ability to attract new customers. To mitigate the reputational harm of negative reviews many firms now publicly respond to them. How effective is this reputation management strategy in improving a firm's reputation? We empirically answer this question by exploiting a difference in managerial practice across two hotel review platforms, TripAdvisor and Expedia: while hotels regularly respond to their TripAdvisor reviews, they almost never do so on Expedia. Based on this observation, we use difference-in-differences to identify the causal impact of management responses on consumer ratings by comparing changes in the TripAdvisor ratings of a hotel following its decision to begin responding against a baseline of changes in the same hotel's Expedia ratings. We find that responding hotels, which account for 56{\%} of hotels in our data, see an average increase of 0.12 stars in the TripAdvisor ratings they receive after they start responding. Moreover, we show that this increase in ratings does not arise from hotel quality investments. Instead, we find that the increase is consistent with a shift in reviewer selection: consumers with a poor experience become less likely to leave a negative review when hotels begin responding.},
author = {Proserpio, Davide and Zervas, Georgios},
doi = {10.2139/ssrn.2521190},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Applied Multivariate Statistics/Project/Online Reputation Management Estimating the Impact of Management Responses on Consumer Reviews.pdf:pdf},
isbn = {978-1-4503-3410-5},
issn = {1556-5068},
journal = {Marketing Science},
keywords = {online reviews,reputation management},
mendeley-groups = {Online Review},
number = {November},
title = {{Online Reputation Management: Estimating the Impact of Management Responses on Consumer Reviews}},
url = {http://www.ssrn.com/abstract=2521190},
year = {2017}
}

@inproceedings{Mukherjee2012,
abstract = {Opinionated social media such as product reviews are now widely used by individuals and organizations for their decision making. However, due to the reason of profit or fame, people try to game the system by opinion spamming (e.g., writing fake reviews) to promote or demote some target products. For reviews to reflect genuine user experiences and opinions, such spam reviews should be detected. Prior works on opinion spam focused on detecting fake reviews and individual fake reviewers. However, a fake reviewer group (a group of reviewers who work collaboratively to write fake reviews) is even more damaging as they can take total control of the sentiment on the target product due to its size. This paper studies spam detection in the collaborative setting, i.e., to discover fake reviewer groups. The proposed method first uses a frequent itemset mining method to find a set of candidate groups. It then uses several behavioral models derived from the collusion phenomenon among fake reviewers and relation models based on the relationships among groups, individual reviewers, and products they reviewed to detect fake reviewer groups. Additionally, we also built a labeled dataset of fake reviewer groups. Although labeling individual fake reviews and reviewers is very hard, to our surprise labeling fake reviewer groups is much easier. We also note that the proposed technique departs from the traditional supervised learning approach for spam detection because of the inherent nature of our problem which makes the classic supervised learning approach less effective. Experimental results show that the proposed method outperforms multiple strong baselines including the state-of-the-art supervised classification, regression, and learning to rank algorithms.},
author = {Mukherjee, Arjun and Liu, Bing and Glance, Natalie},
booktitle = {Proceedings of the 21st international conference on World Wide Web - WWW '12},
doi = {10.1145/2187836.2187863},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Online Review/WWW-2012-group-spam-camera-final.pdf:pdf},
isbn = {9781450312295},
issn = {0025-1909},
keywords = {fake review detection,group opinion spam,opinion spam},
mendeley-groups = {Online Review/Spam Detection},
pages = {191},
title = {{Spotting fake reviewer groups in consumer reviews}},
url = {http://dl.acm.org/citation.cfm?doid=2187836.2187863},
year = {2012}
}
@inproceedings{Ott2012,
abstract = {Consumers' purchase decisions are increasingly influenced by user-generated online reviews. Accordingly, there has been growing concern about the potential for posting decep- tive opinion spam—fictitious reviews that have been deliberately written to sound authentic, to deceive the reader. But while this practice has received considerable public attention and concern, relatively little is known about the actual prevalence, or rate, of deception in online review com- munities, and less still about the factors that influence it. We propose a generativemodel of deception which, in con- junction with a deception classifier, we use to explore the prevalence of deception in six popular online review communities: Expedia, Hotels.com, Orbitz, Priceline, TripAdvisor, and Yelp. We additionally propose a theoretical model of online reviews based on economic signaling theory, in which consumer reviews diminish the inherent information asymmetry between consumers and producers, by acting as a signal to a product's true, unknown quality. We find that deceptive opinion spam is a growing problem overall, but with different growth rates across communities. These rates, we argue, are driven by the different signaling costs associated with deception for each review community, e.g., posting requirements. When measures are taken to increase signaling cost, e.g., filtering reviews written by first-time reviewers, deception prevalence is effectively reduced.},
archivePrefix = {arXiv},
arxivId = {1204.2804v1},
author = {Ott, Myle and Cardie, Claire and Hancock, Jeff},
booktitle = {Proceedings of the 21st international conference on World Wide Web - WWW '12},
doi = {10.1145/2187836.2187864},
eprint = {1204.2804v1},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Online Review/p201-ott.pdf:pdf},
isbn = {9781450312295},
keywords = {Deception prevalence,Deceptive opinion spam,Gibbs sam- pling,Online reviews,Signaling theory},
mendeley-groups = {Online Review/Spam Detection},
pages = {201--210},
title = {{Estimating the prevalence of deception in online review communities}},
url = {http://dl.acm.org/citation.cfm?doid=2187836.2187864},
year = {2012}
}
@article{Zhao2013,
abstract = {We propose a structural model to study the effect of online product$\backslash$nreviews on consumer purchases of experiential products. Such purchases$\backslash$nare characterized by limited repeat purchase behavior of the same$\backslash$nproduct item (such as a book title) but significant past usage experience$\backslash$nwith other products of the same type (such as books of the same genre).$\backslash$nTo cope with the uncertainty in quality of the product item, we posit$\backslash$nthat consumers may learn from their experience with the same type$\backslash$nof product and others' experiences with the product item. We model$\backslash$nthe review credibility as the precision with which product reviews$\backslash$nreflect the consumer's own product evaluation. The higher the precision,$\backslash$nthe more credible the information obtained from product reviews for$\backslash$nthe consumer, and the larger the effect of reviews on the consumer's$\backslash$nchoice probabilities. We extend the Bayesian learning framework to$\backslash$nmodel consumer learning on both product quality and review credibility.$\backslash$nWe apply the model to a panel data set of 1,919 book purchases by$\backslash$n243 consumers. We find that consumers learn more from online reviews$\backslash$nof book titles than from their own experience with other books of$\backslash$nthe same genre. In the counterfactual analysis, we illustrate the$\backslash$nprofit impact of product reviews and how it varies with the number$\backslash$nof reviews. We also study the phenomenon of fake reviews. We find$\backslash$nthat fake reviews increase consumer uncertainty. The effects of more$\backslash$npositive reviews and more numerous reviews on consumer choice are$\backslash$nsmaller on online retailing platforms that have fake product reviews.},
author = {Zhao, Yi and Yang, Sha and Narayan, Vishal and Zhao, Ying},
doi = {10.1287/mksc.1120.0755},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Applied Multivariate Statistics/Project/Modeling Consumer Learning from Online Product Reviews.pdf:pdf},
isbn = {0732-2399},
issn = {0732-2399},
journal = {Marketing Science},
mendeley-groups = {Online Review},
number = {1},
pages = {153--169},
title = {{Modeling Consumer Learning from Online Product Reviews}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mksc.1120.0755},
volume = {32},
year = {2013}
}
@article{Godes2012,
abstract = {W e investigate the evolution of online ratings over time and sequence.We first establish that there exist two distinct dynamic processes, one as a function of the amount of time a book has been available for review and another as a function of the sequence of reviews themselves. We find that, once we control for calendar date, the residual average temporal pattern is increasing. This is counter to existing findings that suggest that without this calendar-date control, the pattern is decreasing. With respect to sequential dynamics, we find that ratings decrease: the nth rating is, on average, lower than the n1th when controlling for time, reviewer effects, and book effects. We test and find some support for existing theories for this decline based on motivation. We then offer two additional explanations for this order effect. We find support for the idea that ones ability to assess the diagnosticity of previous reviews decreases: when previous reviewers are very different, more reviews may thus lead to more purchase errors and lower ratings.},
author = {Godes, David and Silva, Jos{\'{e}} C.},
doi = {10.1287/mksc.1110.0653},
file = {:M$\backslash$:/A Master of Science in Marketing Sciences/Applied Multivariate Statistics/Project/Sequential and Temporal Dynamics of Online Opinion.pdf:pdf},
isbn = {07322399},
issn = {0732-2399},
journal = {Marketing Science},
keywords = {2010,2011,accepted,and bruce hardie served,as associate editor for,august 7,history,in advance,internet marketing,march 25,networks,online reviews,published online in articles,received,russell winer served as,the special issue editor,this article,word of mouth},
mendeley-groups = {Online Review},
number = {3},
pages = {448--473},
pmid = {76388959},
title = {{Sequential and Temporal Dynamics of Online Opinion}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mksc.1110.0653},
volume = {31},
year = {2012}
}
